[[timeseries-dsl]]
== Timeseries Features DSL

Defines how time series data must be aggregated into features
for learning and inference.

Features define how to aggregate numerical data from a `measurement`. +
A `measurement` defines an object type in the data source:

* For Elasticsearch data source, the `measurement` is not used. You can set the `doc_type` in `config.yml` data source settings. Default is `doc` if not set.
* For InfluxDB data source, the `measurement` is the series measurement name.

=== Feature Supported settings

[horizontal]
`name`:: (string) Name given to this feature (must match `^[a-zA-Z0-9-_@]+$`)
`field`:: (string) TSDB column name (must match `^[a-zA-Z0-9-_@.]+$`)
`measurement`:: (string) TSDB table to fetch data (must match `^[a-zA-Z0-9-_@.]+$`)
`match_all`:: (array) List of TSDB tag names and values that must be matched when fetching the data
`metric`:: (Aggregation operator) As supported by the TSDB
`default`:: (float) A default float value to replace NaN values returned by the TSDB, or `previous` in order to fill the series with previous non-NaN value
`transform`:: `null`, or `diff` additional processing to apply to TSDB data in order to generate the feature
`scores`:: `min_max`, or `standardize` additional processing to apply to TSDB data in order to generate the feature
`anomaly_type`:: `low_high`, `low`, or `high` according to the type of abnormal values to detect

=== Aggregation operators
The list below defines the aggregation operators can be used to
define features. These values can be extracted by using numeric
fields in the data source documents.

[options="header"]
|=======================
|Aggregation operator   |Elasticsearch Support      | InfluxDB Support
|`count`                  |True                       |True
|`min`                    |True                       |True
|`max`                    |True                       |True
|`sum`                    |True                       |True
|`avg`                    |True                       |True
|`sum_of_squares`         |True                       |True
|`variance`               |True                       |True
|`std_deviation`          |True                       |True
|`derivative`             |False                      |True
|`integral`               |False                      |True
|`spread`                 |False                      |True
|`mode`                   |False                      |True
|`5percentile`            |False                      |True
|`10percentile`           |False                      |True
|`90percentile`           |False                      |True
|`95percentile`           |False                      |True
|`stddev`                 |False                      |True
|=======================


[NOTE]
==================================================

This version does not support feature generation by a provided script,
nor extracting features from categories ie, non numeric fields.

==================================================


[[dip-user-traffic]]
== A First Example: Abnormal Dips in User Traffic

The easiest time series models have a unique feature. Past values are then
used as a proxy to forecast future values. This unique feature is an `io` ie,
input and output at the same time.

The following `user_traffic.json` file (Or .yml file if YAML format is used)
is using:

* One minute aggregations, ie `bucket_interval` equals 1m
* A forecast horizon equal to 5 `bucket_interval` ie 5 minutes
* A proxy, the span equal to 10 `bucket_interval` ie 10 minutes
* A `low` anomaly type, since we want to detect dips in user traffic

[source,js]
--------------------------------------------------
{
  "bucket_interval": "1m",
  "default_datasource": "my-datasource",
  "features": [
    {
      "default": 0,
      "metric": "count",
      "field": "requests",
      "measurement": "traffic",
      "name": "count_all_requests",
      "anomaly_type": "low"
    }
  ],
  "interval": 60,
  "max_evals": 10,
  "name": "traffic-model",
  "offset": 30,
  "forecast": 5,
  "span": 20,
  "max_threshold": 90,
  "min_threshold": 50,
  "type": "timeseries"
}
--------------------------------------------------


== Advanced Example: Abnormal Dips in User Traffic using Seasonality

Building on the fist example, it is often common for user traffic to have
regular patterns within a given day, and within a given week:

* At night, a smooth decrease
* During the day, one or more sharp increase and decrease eg at lunch time
* During the week-ends or holidays, a totally different pattern

An updated `user_traffic.json` file (Or .yml file if YAML format is used)
will activate seasonality parameters to take it into account:

[source,js]
--------------------------------------------------
{
  "name": "traffic-model",
  "seasonality": {
      "daytime": true,
      "weekday": true
  },
  "bucket_interval": "1m",
  "default_datasource": "my-datasource",
  "features": [
    {
      "default": 0,
      "metric": "count",
      "field": "requests",
      "measurement": "traffic",
      "name": "count_all_requests",
      "anomaly_type": "low"
    }
  ],
  "interval": 60,
  "max_evals": 10,
  "offset": 30,
  "forecast": 5,
  "span": 20,
  "max_threshold": 90,
  "min_threshold": 50,
  "type": "timeseries"
}
--------------------------------------------------

[[times-dsl-multiple-dimensions]]
== Advanced Example: Abnormal Dips in User Traffic using 3 Dimensions

Again, building on the previous example we could try to enhance the model
accuracy, ie lower loss, and forecast the user traffic based on additional features:

* Past user traffic, using past values as a proxy to guess the future values
* Active users count at a given time
* The click through rate, ie CTR, as measured in social media campaigns

The features list becomes a dictionary with 3 optional lists, `i`, `o`, and `io`
respectively for input, output, and input-output features:

* Two dimensions will be used to ingest input data in the model, and therefore are declared in the `i` features list
* One dimension, the user traffic, is both an input and the expected output therefore it is declared in the `io` features list

Effectively, the following file gives you a model to forecast and detect
anomalies in user traffic as a function of past user traffic, past active users,
and past click through rate in advertising campaigns.

An updated `user_traffic.json` file (Or .yml file if YAML format is used)
will become:

--------------------------------------------------
{
  "name": "traffic-model",
  "seasonality": {
      "daytime": true,
      "weekday": true
  },
  "bucket_interval": "1m",
  "default_datasource": "my-datasource",
  "features": {
    "io": [{
      "default": 0,
      "metric": "count",
      "field": "requests",
      "measurement": "traffic",
      "name": "count_all_requests",
      "anomaly_type": "low"
    }],
    "i": [
      {
      "default": 0,
      "metric": "max",
      "field": "active_users",
      "measurement": "traffic",
      "name": "max_users"
      },
      {
      "default": 0,
      "metric": "mean",
      "field": "click_through_rate",
      "measurement": "social",
      "name": "avg_ctr"
      }
    ]
  },
  "interval": 60,
  "max_evals": 10,
  "offset": 30,
  "forecast": 5,
  "span": 20,
  "max_threshold": 90,
  "min_threshold": 50,
  "type": "timeseries"
}
--------------------------------------------------

== Advanced Example: Abnormal Dips in User Traffic using Filters

Again, building on the previous example we can use the `match_all` property
to query only GoogleAds click through rates from the social media measurement.

One or more `match_all` conditions can be added and will automatically 
change the queries to your data sources with the right filters.

An updated `user_traffic.json` file (Or .yml file if YAML format is used)
will become:

--------------------------------------------------
{
  "name": "traffic-model",
  "seasonality": {
      "daytime": true,
      "weekday": true
  },
  "bucket_interval": "1m",
  "default_datasource": "my-datasource",
  "features": {
    "io": [{
      "default": 0,
      "metric": "count",
      "field": "requests",
      "measurement": "traffic",
      "name": "count_all_requests",
      "anomaly_type": "low"
    }],
    "i": [
      {
      "default": 0,
      "metric": "max",
      "field": "active_users",
      "measurement": "traffic",
      "name": "max_users"
      },
      {
      "default": 0,
      "metric": "mean",
      "field": "click_through_rate",
      "measurement": "social",
      "match_all": [
        {"tag": "channel", "value": "GoogleAds"}
      ],
      "name": "avg_ctr_googleads"
      }
    ]
  },
  "interval": 60,
  "max_evals": 10,
  "offset": 30,
  "forecast": 5,
  "span": 20,
  "max_threshold": 90,
  "min_threshold": 50,
  "type": "timeseries"
}
--------------------------------------------------
